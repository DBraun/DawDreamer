{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d9ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from os.path import abspath\n",
    "from os.path import isfile\n",
    "from os.path import basename\n",
    "from os.path import splitext\n",
    "from os.path import abspath\n",
    "from glob import glob\n",
    "import re\n",
    "import random\n",
    "import warnings\n",
    "import datetime\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "\n",
    "# installable with pip\n",
    "import tqdm\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "\n",
    "import dawdreamer as daw\n",
    "\n",
    "# The last cells in this notebook are optional and are for making a movie.\n",
    "# You must install imagemagick and set an environment variable to magick.exe. See the MoviePy installation instructions.\n",
    "# You must also install eyed3.\n",
    "\n",
    "def get_timestamp():\n",
    "    \n",
    "    return datetime.datetime.now().strftime(\"%y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f6a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions:\n",
    "# You must have files named with the \"Mixed In Key\" Circle of Fifths convention.\n",
    "# An example is \"8A - 130 - My Song.wav\"\n",
    "# In this example, the letter A represents a \"minor\" key. B would have represented a major key.\n",
    "# Specifically 8A refers to A Minor and 8B refers to C Major. These keys share the same\n",
    "# notes, but they are distinguished by this letter.\n",
    "# The number 12 could be between 1 through 12 and it represents going around the Circle of Fifths while\n",
    "# staying in the same kind of key (major/minor).\n",
    "# You can look up the diagram on your favorite search engine.\n",
    "\n",
    "LYRICS_FOLDERS = [\"E:/Ableton/Samples/Beatmatched Vocals-Lyrics/\"]\n",
    "MELODY_FOLDERS = [\"E:/Ableton/Samples/Beatmatched/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9bc1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioClip():\n",
    "    \n",
    "    def __init__(self, asd_path, wav_path, name, bpm=120, key='8', mode='A'):\n",
    "        self.asd_path = asd_path\n",
    "        self.wav_path = wav_path\n",
    "        self.name = name\n",
    "        self.bpm = bpm\n",
    "        self.key = key\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return f'AudioClip(bpm={self.bpm},key={self.key},mode={self.mode},name={self.name})'\n",
    "        \n",
    "def parse_asd_paths_to_clips(asd_paths):\n",
    "    \n",
    "    audioclips = []\n",
    "    \n",
    "    r = r\"\"\"(\\d{1,2})(A|B)\\s-\\s(\\d*)\\s-\\s(.*)\"\"\"\n",
    "    reg = re.compile(r)\n",
    "\n",
    "    for asd_path in asd_paths:\n",
    "\n",
    "        wav_path = asd_path[:-4]\n",
    "        if not isfile(wav_path):\n",
    "            continue\n",
    "\n",
    "        b = splitext(basename(wav_path).strip())[0]\n",
    "        match = reg.search(b)\n",
    "\n",
    "        if not match:\n",
    "            print(f'Circle of Fifths regex failed for file: {b}')\n",
    "            continue\n",
    "\n",
    "        audioclip = AudioClip(asd_path, wav_path, match.group(4), bpm=int(match.group(3)), key=int(match.group(1)),\n",
    "                              mode=match.group(2))        \n",
    "        audioclips.append(audioclip)\n",
    "    \n",
    "    return audioclips\n",
    "\n",
    "\n",
    "def get_pairs(clips_a, clips_b, num_desired, dist_threshold=3.5, MAX_ATTEMPTS=100000, with_replacement=True):\n",
    "    \n",
    "    def dist_func(clip_a, clip_b):\n",
    "\n",
    "        dist = np.zeros((3,1))\n",
    "\n",
    "        # compare 7B to 12B for example (5 away). Note that 1 is 1 away from 12.\n",
    "        dist[0] += min(abs(clip_a.key-clip_b.key), 12-abs(clip_a.key-clip_b.key))\n",
    "        \n",
    "        if clip_a.mode != clip_b.mode:\n",
    "            dist[1] += 0.5\n",
    "\n",
    "        # give distance according to bpm difference\n",
    "        avg_bpm = (clip_a.bpm + clip_b.bpm)/2.\n",
    "        dist[2] += (abs(clip_a.bpm - clip_b.bpm)/avg_bpm)/.05\n",
    "\n",
    "        return np.linalg.norm(dist)\n",
    "\n",
    "    pairs = []\n",
    "\n",
    "    attempts = 0\n",
    "    num_added = 0\n",
    "    \n",
    "    while clips_a and clips_b and num_added < num_desired and attempts < MAX_ATTEMPTS:\n",
    "        attempts += 1\n",
    "\n",
    "        clip_a = random.choice(clips_a)\n",
    "        clip_b = random.choice(clips_b)\n",
    "        dist = dist_func(clip_a, clip_b)\n",
    "        if dist < dist_threshold:\n",
    "            pairs.append([clip_a, clip_b])\n",
    "            num_added += 1\n",
    "            \n",
    "            if not with_replacement:\n",
    "                clips_a.remove(clip_a)\n",
    "                clips_b.remove(clip_b)\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5217e6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_asd_paths = reduce(add,[list(glob(folder+'*.asd')) for folder in LYRICS_FOLDERS])\n",
    "melody_asd_paths = reduce(add,[list(glob(folder+'*.asd')) for folder in MELODY_FOLDERS])\n",
    "\n",
    "vocal_asd_paths = [x.replace('\\\\', '/') for x in vocal_asd_paths]\n",
    "melody_asd_paths = [x.replace('\\\\', '/') for x in melody_asd_paths]\n",
    "\n",
    "vocal_clips = parse_asd_paths_to_clips(vocal_asd_paths)\n",
    "melody_clips = parse_asd_paths_to_clips(melody_asd_paths)\n",
    "\n",
    "num_desired = 5\n",
    "dist_threshold=3.3\n",
    "with_replacement = False\n",
    "\n",
    "pairs = get_pairs(vocal_clips, melody_clips, num_desired, dist_threshold=dist_threshold, with_replacement=with_replacement)\n",
    "# print('VOCAL' + ' '*46 + '| MELODY')\n",
    "# for vocal_clip, melody_clip in pairs:\n",
    "#     print(vocal_clip.name[:50] + (' '*(50-len(vocal_clip.name)))+ ' | ' + melody_clip.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86aedc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 44100\n",
    "BLOCK_SIZE = 512\n",
    "\n",
    "def load_audio_file(file_path, duration=None):\n",
    "    \n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "\n",
    "    #import soundfile\n",
    "    #sig, rate = soundfile.read(file_path, always_2d=True, samplerate=SAMPLE_RATE, stop=int(duration*SAMPLE_RATE))\t\n",
    "\n",
    "    sig, rate = librosa.load(file_path, duration=duration, mono=False, sr=SAMPLE_RATE)\n",
    "    assert(rate == SAMPLE_RATE)\n",
    "    \n",
    "    if sig.ndim == 1:\n",
    "        sig = np.stack([sig,sig])\n",
    "    \n",
    "    return sig\n",
    "\n",
    "def render(engine, file_path=None, duration=5.):\n",
    "\n",
    "    engine.render(duration)\n",
    "\n",
    "    output = engine.get_audio()\n",
    "\n",
    "    if file_path is not None:\n",
    "\n",
    "        wavfile.write(file_path, SAMPLE_RATE, output.transpose())\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a705ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = daw.RenderEngine(SAMPLE_RATE, BLOCK_SIZE)\n",
    "\n",
    "vocal_processor = engine.make_playbackwarp_processor(\"vocals\", np.zeros((2, 1)))\n",
    "melody_processor = engine.make_playbackwarp_processor(\"melody\", np.zeros((2, 1)))\n",
    "\n",
    "graph = [\n",
    "    (vocal_processor, []),\n",
    "    (melody_processor, []),\n",
    "    (engine.make_add_processor(\"add\", [.7, .7]), [\"vocals\", \"melody\"])\n",
    "]\n",
    "\n",
    "assert(engine.load_graph(graph))\n",
    "\n",
    "all_audio = np.zeros((2, 0))\n",
    "\n",
    "durations = []\n",
    "\n",
    "for vocal_clip, melody_clip in tqdm.tqdm(pairs, desc=\"Rendering audio\"):\n",
    "\n",
    "    # average the bpms\n",
    "    bpm = (vocal_clip.bpm+melody_clip.bpm)/2.\n",
    "    engine.set_bpm(bpm)\n",
    "    \n",
    "    num_quarter_notes = 16\n",
    "\n",
    "    duration = num_quarter_notes * (60./bpm)\n",
    "\n",
    "    print('melody_clip.wav_path: ', melody_clip.wav_path)\n",
    "    data = load_audio_file(melody_clip.wav_path)\n",
    "    print('set data')\n",
    "    melody_processor.set_data(data)\n",
    "    print('vocal_clip.wav_path: ', vocal_clip.wav_path)\n",
    "    data = load_audio_file(vocal_clip.wav_path)\n",
    "    print('set data')\n",
    "    vocal_processor.set_data(data)\n",
    "\n",
    "    print('melody_processor.set_clip_file')\n",
    "    if not melody_processor.set_clip_file(melody_clip.asd_path):\n",
    "        durations.append(0.)\n",
    "        continue\n",
    "\n",
    "    print('vocal_processor.set_clip_file')\n",
    "    if not vocal_processor.set_clip_file(vocal_clip.asd_path):\n",
    "        durations.append(0.)\n",
    "        continue\n",
    "\n",
    "    durations.append(duration)\n",
    "\n",
    "#     print('melody_processor.start_marker: ', melody_processor.start_marker)\n",
    "#     print('melody_processor.end_marker: ', melody_processor.end_marker)\n",
    "#     print('melody_processor.loop_on: ', melody_processor.loop_on)\n",
    "#     print('melody_processor.loop_start: ', melody_processor.loop_start)\n",
    "#     print('melody_processor.loop_end: ', melody_processor.loop_end)\n",
    "#     print('melody_processor.warp_on: ', melody_processor.warp_on)\n",
    "\n",
    "#     print('vocal_processor.start_marker: ', vocal_processor.start_marker)\n",
    "#     print('vocal_processor.end_marker: ', vocal_processor.end_marker)\n",
    "#     print('vocal_processor.loop_on: ', vocal_processor.loop_on)\n",
    "#     print('vocal_processor.loop_start: ', vocal_processor.loop_start)\n",
    "#     print('vocal_processor.loop_end: ', vocal_processor.loop_end)\n",
    "#     print('vocal_processor.warp_on: ', vocal_processor.warp_on)\n",
    "\n",
    "    print('render')\n",
    "    engine.render(duration)\n",
    "\n",
    "    all_audio = np.concatenate([all_audio, engine.get_audio()], axis=-1)\n",
    "\n",
    "# convert from float 32 to int16\n",
    "all_audio_out = (np.iinfo(np.int16).max * (all_audio / np.max(all_audio))).astype(np.int16)\n",
    "wavfile.write(f'output/all_audio_{get_timestamp()}.wav', SAMPLE_RATE, all_audio_out.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c7c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This optional section is for making a movie.\n",
    "# You must install imagemagick and set an environment variable to magick.exe. See the MoviePy installation instructions.\n",
    "# You must also install eyed3.\n",
    "from moviepy.editor import *\n",
    "from moviepy.audio.AudioClip import AudioArrayClip\n",
    "import eyed3\n",
    "\n",
    "screensize = (1280,720)\n",
    "\n",
    "def audioclip_to_title(audioclip):\n",
    "    \n",
    "    try:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            audio_meta = eyed3.load(audioclip.wav_path)\n",
    "            if audio_meta:\n",
    "                return f'{audioclip.key}{audioclip.mode} - {audioclip.bpm}\\n{audio_meta.tag.artist}\\n{audio_meta.tag.title}'\n",
    "            else:\n",
    "                print(f'ID3 not recognized for file: {audioclip.wav_path}')\n",
    "    except IOError as e:\n",
    "        print(f'Unrecognized file: {audioclip.wav_path}')\n",
    "    except Exception as e:\n",
    "        print(f'Error loading ID3 tags from file: {audioclip.wav_path}')\n",
    "    \n",
    "    return audioclip.name\n",
    "\n",
    "total_duration = 0.\n",
    "video_clips = []\n",
    "for (vocal_clip, melody_clip), duration in zip(pairs, durations):\n",
    "    \n",
    "    bpm = (vocal_clip.bpm+melody_clip.bpm)/2.\n",
    "    engine.set_bpm(bpm)\n",
    "    \n",
    "    if duration == 0.:\n",
    "        continue\n",
    "    total_duration += duration\n",
    "    \n",
    "    txt = f'{audioclip_to_title(vocal_clip)}\\n\\n&\\n\\n{audioclip_to_title(melody_clip)}'\n",
    "    txtClip = TextClip(txt, color='white', font=\"Amiri-Bold\", kerning=2, fontsize=36, size=screensize).set_duration(duration)\n",
    "    \n",
    "    video_clips.append(txtClip)\n",
    "\n",
    "final_clip = concatenate_videoclips(video_clips)\n",
    "final_clip.audio = AudioArrayClip(all_audio.transpose(), fps=SAMPLE_RATE)\n",
    "final_clip.write_videofile(f'output/my_movie_{get_timestamp()}.mp4',fps=4,codec='mpeg4')\n",
    "    \n",
    "# showing video \n",
    "final_clip.ipython_display(width=720, fps=10, maxduration=60*15.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda73af6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filepath = \"E:/Ableton/Samples/Beatmatched Vocals-Lyrics/2A - 80 - Who Run It (Acappella).mp3\"\n",
    "data = load_audio_file(filepath)\n",
    "print(data.shape)\n",
    "engine = daw.RenderEngine(SAMPLE_RATE, BLOCK_SIZE)\n",
    "vocal_processor = engine.make_playbackwarp_processor(\"vocals\", data)\n",
    "assert(vocal_processor.set_clip_file(filepath+'.asd'))\n",
    "vocal_processor.warp_markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236ce9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.remove('__temp__.mp4')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
